{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apiiit-rkv/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/apiiit-rkv/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/apiiit-rkv/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/apiiit-rkv/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/apiiit-rkv/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/apiiit-rkv/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/apiiit-rkv/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/apiiit-rkv/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/apiiit-rkv/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/apiiit-rkv/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/apiiit-rkv/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/apiiit-rkv/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (64,64)\n",
    "def pixels_from_path(file_path):\n",
    "    im = Image.open(file_path)\n",
    "    im = im.resize(IMG_SIZE)\n",
    "    np_im = np.array(im)\n",
    "    #matrix of pixel RGB values\n",
    "    return np_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/apiiit-rkv/Desktop/TRAIN/horse-116.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.60.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-20.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-68.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.53.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-78.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.43.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-24.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-85.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-52.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.113.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.97.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-100.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.66.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-98.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.37.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-7.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.84.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.48.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-48.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-57.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.88.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.34.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.18.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.20.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.14.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.31.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.75.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-28.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-18.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-15.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.78.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.40.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-90.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.54.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-95.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-74.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-67.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.19.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.117.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.7.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.63.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.23.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.80.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-112.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-11.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.13.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-80.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.46.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.35.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.30.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-54.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-19.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.52.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-23.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.104.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-9.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-43.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-109.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.51.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.92.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-53.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.22.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.55.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.72.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-120.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.1.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.85.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.67.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-108.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-63.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.9.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.50.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-39.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-17.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-79.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-8.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-111.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-6.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-91.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.12.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.41.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-65.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.27.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.99.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-3.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-22.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-62.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-30.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.115.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.25.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.44.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-114.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.24.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.82.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-103.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.26.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.2.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-10.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.102.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.109.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-5.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-1.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-71.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-50.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.98.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.110.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-118.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-27.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.32.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-42.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-61.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-59.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.39.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-29.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-93.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.38.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-12.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.61.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.59.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-46.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.79.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-58.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.16.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.91.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-106.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.73.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-38.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.96.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-86.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.101.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.57.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-56.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-16.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.74.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.3.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.87.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-51.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-81.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.77.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-33.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-99.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-107.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.11.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.111.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.69.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.108.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.58.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-89.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-2.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-47.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-75.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-92.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-87.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.62.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-44.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-34.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-32.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.81.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-69.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-73.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.4.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-94.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-36.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-60.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.86.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-37.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-70.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.106.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.71.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.76.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.47.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-66.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-105.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-45.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.68.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-14.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.118.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-102.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.93.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-4.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-64.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-104.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-117.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-101.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.49.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.116.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.8.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-82.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.36.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-97.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-26.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.33.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-31.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-84.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.70.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.89.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-76.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.100.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-115.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-55.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.28.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.83.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.94.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-88.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-13.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.112.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.90.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-41.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.105.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-96.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.5.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-72.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.45.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-21.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.64.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.15.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.29.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.114.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.65.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.17.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.42.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.21.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-25.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.119.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-119.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.120.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.107.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-49.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.103.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.95.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-110.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-35.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-83.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.6.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-40.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-77.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.10.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/dog.56.jpg',\n",
       " '/home/apiiit-rkv/Desktop/TRAIN/horse-113.jpg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob('/home/apiiit-rkv/Desktop/TRAIN/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "shape_counts = defaultdict(int)\n",
    "for i, cat in enumerate(glob.glob('/home/apiiit-rkv/Desktop/tot/tottrain/dog/*')[:1000]):\n",
    "    if i%100==0:\n",
    "        print(i)\n",
    "    img_shape = pixels_from_path(cat).shape\n",
    "    shape_counts[str(img_shape)]= shape_counts[str(img_shape)]+ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_items = list(shape_counts.items())\n",
    "shape_items.sort(key = lambda x: x[1])\n",
    "shape_items.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10% of the data will automatically be used for validation\n",
    "validation_size = 0.1\n",
    "img_size = IMG_SIZE # resize images to be 374x500 (most common shape)\n",
    "num_channels = 3 # RGB\n",
    "sample_size = 8192 #We'll use 8192 pictures (2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glob.glob('/home/apiiit-rkv/Desktop/tot/tottrain/dog/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixels_from_path(glob.glob('/home/apiiit-rkv/Desktop/tot/tottrain/dog/*')[5]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training dog images...\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_SIZE = 120\n",
    "#print(\"loading trainin cat images...\")\n",
    "#cat_train_set = np.asarray([pixels_from_path(cat) for cat in glob.glob('/home/apiiit-rkv/Desktop/tot/tottrain/horse/*')[:SAMPLE_SIZE]])\n",
    "print(\"loading training dog images...\")\n",
    "dog_train_set = np.asarray([pixels_from_path(dog) for dog in glob.glob('/home/apiiit-rkv/Desktop/tot/tottrain/dog/*')[:SAMPLE_SIZE]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading validation dog images...\n"
     ]
    }
   ],
   "source": [
    "valid_size = 34\n",
    "print(\"loading validation dog images...\")\n",
    "dog_valid_set = np.asarray([pixels_from_path(cat) for cat in glob.glob('/home/apiiit-rkv/Desktop/tot/tottest/dog/*')[-valid_size:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120,)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.concatenate([dog_train_set])\n",
    "#labels_train = np.asarray([1 for _ in range(SAMPLE_SIZE)]+[0 for _ in range(SAMPLE_SIZE)])\n",
    "labels_train = np.asarray([1 for _ in range(SAMPLE_SIZE)])\n",
    "print(labels_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34,)\n"
     ]
    }
   ],
   "source": [
    "x_valid = np.concatenate([ dog_valid_set])\n",
    "labels_valid = np.asarray([1 for _ in range(valid_size)])\n",
    "print(labels_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 64, 64, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run of the Mill MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "total_pixels = img_size[0] *img_size[1] * 3\n",
    "fc_size = 512\n",
    "\n",
    "inputs = keras.Input(shape=(img_size[1], img_size[0],3), name='ani_image')\n",
    "x = layers.Flatten(name = 'flattened_img')(inputs) #turn image to vector.\n",
    "\n",
    "x = layers.Dense(fc_size, activation='relu', name='first_layer')(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid', name='class')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "model2=Sequential()\n",
    "input_shape=(64,64,3)\n",
    "model2 = Sequential(layers=[\n",
    "    # input layers and convolutional layers\n",
    "    Conv2D(128, kernel_size=(3,3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Conv2D(256, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_counts = defaultdict(int)\n",
    "for i, cat in enumerate(glob.glob('/home/apiiit-rkv/Desktop/tot/tottrain/horse/*')[:1000]):\n",
    "    if i%100==0:\n",
    "        print(i)\n",
    "    img_shape = pixels_from_path(cat).shape\n",
    "    shape_counts[str(img_shape)]= shape_counts[str(img_shape)]+ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_items = list(shape_counts.items())\n",
    "shape_items.sort(key = lambda x: x[1])\n",
    "shape_items.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size = 0.1\n",
    "img_size = IMG_SIZE # resize images to be 374x500 (most common shape)\n",
    "num_channels = 3 # RGB\n",
    "sample_size = 8192 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glob.glob('/home/apiiit-rkv/Desktop/tot/tottrain1/horse/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixels_from_path(glob.glob('/home/apiiit-rkv/Desktop/tot/tottrain1/horse/*')[5]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training horseimages...\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_SIZE = 120\n",
    "#print(\"loading trainin cat images...\")\n",
    "#cat_train_set = np.asarray([pixels_from_path(cat) for cat in glob.glob('/home/apiiit-rkv/Desktop/tot/tottrain/horse/*')[:SAMPLE_SIZE]])\n",
    "print(\"loading training horseimages...\")\n",
    "horse_train_set = np.asarray([pixels_from_path(horse) for horse in glob.glob('/home/apiiit-rkv/Desktop/tot/tottrain1/horse/*')[:SAMPLE_SIZE]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading validation horseimages...\n"
     ]
    }
   ],
   "source": [
    "valid_size = 34\n",
    "print(\"loading validation horseimages...\")\n",
    "horse_valid_set = np.asarray([pixels_from_path(horse) for horse in glob.glob('/home/apiiit-rkv/Desktop/tot/tottest1/horse/*')[-valid_size:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "x_train1 = np.concatenate([horse_train_set])\n",
    "#labels_train = np.asarray([1 for _ in range(SAMPLE_SIZE)]+[0 for _ in range(SAMPLE_SIZE)])\n",
    "labels_train1 = np.asarray([0 for _ in range(SAMPLE_SIZE)])\n",
    "print(labels_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "x_valid1 = np.concatenate([ horse_valid_set])\n",
    "labels_valid1 = np.asarray([0 for _ in range(valid_size)])\n",
    "print(labels_valid1.shape)\n",
    "print(labels_valid1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "model1=Sequential()\n",
    "input_shape=(64,64,3)\n",
    "model1 = Sequential(layers=[\n",
    "    # input layers and convolutional layers\n",
    "    Conv2D(128, kernel_size=(3,3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Conv2D(256, kernel_size=(3,3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_concat = concatenate([model1.output, model2.output], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_concat= Flatten()(model_concat)\n",
    "model_concat = Dense(1, activation='softmax')(model_concat)\n",
    "model = Model(inputs=[model1.input, model2.input], outputs=model_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv2d_2_input (InputLayer)     [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_input (InputLayer)       [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 62, 62, 128)  3584        conv2d_2_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 62, 62, 128)  3584        conv2d_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 31, 31, 128)  0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 31, 31, 128)  0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 29, 29, 256)  295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 29, 29, 256)  295168      max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 256)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 256)  0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 14, 14, 512)  0           max_pooling2d_3[0][0]            \n",
      "                                                                 max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 100352)       0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            100353      flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 697,857\n",
      "Trainable params: 697,857\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-33-d0007e11bc2f>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-33-d0007e11bc2f>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    steps_per_epoch = 5,\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#fitted_model = model.fit([x_train,x_train1],\n",
    "                        steps_per_epoch = 5,\n",
    "                        epochs = 5,\n",
    "                        validation_data = [x_valid,x_valid1],\n",
    "                        validation_steps = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(labels_train)\n",
    "print(labels_valid)\n",
    "print(labels_train1)\n",
    "print(labels_valid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from numpy  import *   \n",
    "out_u=matrix(np.zeros(120))\n",
    "out_sig=matrix(np.ones(120))\n",
    "out_both = concatenate([out_u, out_sig], axis=1)\n",
    "print(out_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120,)\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_SIZE=60\n",
    "labels_train = np.asarray([1 for _ in range(SAMPLE_SIZE)]+[0 for _ in range(SAMPLE_SIZE)])\n",
    "print(labels_train.shape)\n",
    "print(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "(34,)\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_SIZE=17\n",
    "labels_valid = np.asarray([1 for _ in range(SAMPLE_SIZE)]+[0 for _ in range(SAMPLE_SIZE)])\n",
    "print(labels_valid)\n",
    "\n",
    "print(labels_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "concatenate() got an unexpected keyword argument 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-9f8b9549f112>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout_both\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'concatenate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mout_both1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_valid1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'concatenate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: concatenate() got an unexpected keyword argument 'name'"
     ]
    }
   ],
   "source": [
    "\n",
    "out_both = concatenate([x_train, x_train1], axis=1, name = 'concatenate')\n",
    "out_both1 = concatenate([x_valid, x_valid1], axis=1, name = 'concatenate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/apiiit-rkv/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 120 samples, validate on 34 samples\n",
      "Epoch 1/10\n",
      " 32/120 [=======>......................] - ETA: 42s - loss: 7.6666 - accuracy: 0.5000"
     ]
    }
   ],
   "source": [
    "epoch=10\n",
    "history = model.fit([x_train,x_train1],\n",
    "                    [labels_train],\n",
    "                    shuffle = True, #important since we loaded cats first, dogs second.\n",
    "                    epochs=10,\n",
    "                    validation_data=([x_valid,x_valid1], labels_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14*14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "x_train = np.concatenate([dog_train_set, horse_train_set])\n",
    "labels_train = np.asarray([1 for _ in range(SAMPLE_SIZE)]+[0 for _ in range(SAMPLE_SIZE)])\n",
    "x_valid = np.concatenate([dog_valid_set, horse_valid_set])\n",
    "labels_valid = np.asarray([1 for _ in range(valid_size)]+[0 for _ in range(valid_size)])\n",
    "print(labels_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([[[[112, 135, 127],\n         [114, 137, 129],\n         [108, 131, 123],\n         ...,\n         [114, 132, 132],\n         [112, 130, 130],\n         [113, 131, 131]],\n\n        [[107, 130, 122],\n ...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-222-acea33d9abb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#important since we loaded cats first, dogs second.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     validation_data=(x_valid, labels_valid))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2426\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2427\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2428\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2430\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    477\u001b[0m                        \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                        \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m                        str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    480\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m       raise ValueError('Error when checking model ' + exception_prefix +\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([[[[112, 135, 127],\n         [114, 137, 129],\n         [108, 131, 123],\n         ...,\n         [114, 132, 132],\n         [112, 130, 130],\n         [113, 131, 131]],\n\n        [[107, 130, 122],\n ..."
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, \n",
    "                    labels_train,\n",
    "                    batch_size=32, \n",
    "                    shuffle = True, #important since we loaded cats first, dogs second.\n",
    "                    epochs=10,\n",
    "                    validation_data=(x_valid, labels_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
